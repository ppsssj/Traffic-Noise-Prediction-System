# ============================================================
# noise_predictor_filtered.py (í•­ê³µê¸°/í—¬ë¦¬ì½¥í„° ì œì™¸ ë²„ì „)
# ============================================================
import os, json, glob, re, joblib, warnings
import pandas as pd
import numpy as np
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from catboost import CatBoostRegressor, Pool
warnings.filterwarnings("ignore")

# ============================================================
# 1) JSON ë³‘í•©
# ============================================================
json_dir = "./noise_data"
all_json = glob.glob(os.path.join(json_dir, "*.json"))

def parse_json(path):
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    rows = []
    for ann in data.get("annotations", []):
        env = data.get("environment", {}) or {}
        gps = env.get("gps", {}) or {}
        audio = data.get("audio", {}) or {}
        cat = ann.get("categories", {}) or {}

        try:
            hour = int(str(env.get("recordingTime", "")).split(":")[0])
        except:
            hour = np.nan

        m = re.search(r"(\d+)", str(env.get("distance", "")))
        dist = int(m.group(1)) if m else np.nan

        rows.append({
            "hour": hour,
            "dayNight": env.get("dayNight"),
            "urban": env.get("urban"),
            "district": env.get("district"),
            "place": env.get("place"),
            "areaUse": env.get("areaUse"),
            "weather": env.get("weather"),
            "distance_m": dist,
            "obstacle": env.get("obstacle"),
            "latitude": gps.get("latitude"),
            "longitude": gps.get("longitude"),
            "duration": audio.get("duration"),
            "sampleRate_kHz": float(re.sub(r"[^\d.]", "", str(audio.get("sampleRate", "")) or "0") or 0),
            "category_01": cat.get("category_01"),
            "category_02": cat.get("category_02"),
            "category_03": cat.get("category_03"),
            "subCategory": ann.get("subCategory"),
            "decibel": ann.get("decibel")
        })
    return rows


# ============================================================
# 2) ë°ì´í„° ë³‘í•© ë° í•„í„°ë§
# ============================================================
records = []
for f in tqdm(all_json, desc="ğŸ“‚ JSON ë³‘í•© ì¤‘"):
    records.extend(parse_json(f))
df = pd.DataFrame(records)
print(f"âœ… JSON ë³‘í•© ì™„ë£Œ: {len(df)}")

req_cols = ["decibel","hour","weather","urban","category_02","category_03"]
df = df.dropna(subset=req_cols).copy()

# í•­ê³µê¸°/í—¬ë¦¬ì½¥í„° ì œì™¸
exclude_list = ["í•­ê³µê¸°", "ë¹„í–‰ê¸°", "í—¬ë¦¬ì½¥í„°"]
df = df[~df["category_02"].isin(exclude_list)].copy()
print("ğŸš« í•­ê³µê¸°/í—¬ë¦¬ì½¥í„° ì œì™¸ ì™„ë£Œ")
print("ğŸ“Š ë‚¨ì€ category_02 ë¶„í¬:")
print(df["category_02"].value_counts())

# ============================================================
# 3) Feature Engineering
# ============================================================
df["sin_hour"] = np.sin(2*np.pi*df["hour"]/24)
df["cos_hour"] = np.cos(2*np.pi*df["hour"]/24)
df["is_daytime"] = df["hour"].apply(lambda x: 1 if 6 <= x <= 20 else 0)
df["log_distance"] = np.log1p(df["distance_m"].fillna(10))
df["weather_daytime"] = df["weather"].astype(str) + "_" + df["is_daytime"].astype(str)
df["urban_x_weather"] = df["urban"].astype(str) + "_" + df["weather"].astype(str)
df["hour_group"] = pd.cut(df["hour"], bins=[-1,6,12,18,24], labels=["ë°¤","ì˜¤ì „","ì˜¤í›„","ì•¼ê°„"])
df["weather_simple"] = df["weather"].replace({"ë§‘ìŒ":"ì¢‹ìŒ","íë¦¼":"ë‚˜ì¨","ë¹„":"ë‚˜ì¨","ëˆˆ":"ë‚˜ì¨"})

feature_cols = [
    "hour","sin_hour","cos_hour","is_daytime","log_distance",
    "latitude","longitude","duration","sampleRate_kHz",
    "dayNight","urban","district","place","areaUse","weather","obstacle",
    "category_01","category_02","category_03","subCategory",
    "weather_daytime","urban_x_weather","hour_group","weather_simple"
]
cat_cols = df[feature_cols].select_dtypes(include=["object","category"]).columns.tolist()
cat_idx = [feature_cols.index(c) for c in cat_cols]

# ============================================================
# 4) í•™ìŠµ ë£¨í”„ (ìë™ì°¨ / ì´ë¥œìë™ì°¨ / ì—´ì°¨)
# ============================================================
vehicle_groups = df["category_02"].unique().tolist()
print("ğŸš— í•™ìŠµ ëŒ€ìƒ ì¢…ë¥˜:", vehicle_groups)
models = {}

for vtype in vehicle_groups:
    subset = df[df["category_02"] == vtype]
    if len(subset) < 50:
        print(f"âš ï¸ {vtype} ë°ì´í„° ë¶€ì¡± ({len(subset)}) â†’ ê±´ë„ˆëœ€")
        continue

    idx_train, idx_test = train_test_split(
        subset.index,
        stratify=subset["category_03"],
        test_size=0.2,
        random_state=42
    )
    train_df = subset.loc[idx_train].copy()
    test_df = subset.loc[idx_test].copy()

    for col in train_df.select_dtypes(include="object").columns:
        train_df[col] = train_df[col].fillna("None").astype(str)
    for col in test_df.select_dtypes(include="object").columns:
        test_df[col] = test_df[col].fillna("None").astype(str)

    X_train = train_df[feature_cols]
    y_train = train_df["decibel"].astype(float)
    X_test = test_df[feature_cols]
    y_test = test_df["decibel"].astype(float)

    train_pool = Pool(X_train, y_train, cat_features=cat_idx)
    test_pool = Pool(X_test, y_test, cat_features=cat_idx)

    model = CatBoostRegressor(
        loss_function="MAE",
        iterations=1000,
        depth=8,
        learning_rate=0.03,
        subsample=0.8,
        random_seed=42,
        eval_metric="MAE",
        od_type="Iter",
        od_wait=150,
        verbose=200
    )
    model.fit(train_pool, eval_set=test_pool, use_best_model=True)

    pred = model.predict(test_pool)
    mae = mean_absolute_error(y_test, pred)
    r2 = r2_score(y_test, pred)
    print(f"âœ… {vtype} ì™„ë£Œ: MAE={mae:.2f}, RÂ²={r2:.3f}")

    models[vtype] = model
    joblib.dump(model, f"noise_model_{vtype}.pkl")

# ============================================================
# 5) í”¼ì²˜ ëª©ë¡ ì €ì¥
# ============================================================
with open("feature_list.json","w",encoding="utf-8") as f:
    json.dump(feature_cols, f, ensure_ascii=False, indent=2)
with open("cat_cols.json","w",encoding="utf-8") as f:
    json.dump(cat_cols, f, ensure_ascii=False, indent=2)
print("ğŸ’¾ ëª¨ë“  ëª¨ë¸ ì €ì¥ ì™„ë£Œ:", list(models.keys()))
